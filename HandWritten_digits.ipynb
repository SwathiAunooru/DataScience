{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HandWritten_digits.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwathiAunooru/DataScience/blob/master/HandWritten_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJjiEOEabpZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYMWSMyAdN-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54Gbg0ZbdjJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "12f60f0d-bbed-45c3-af47-36ded3bd9f16"
      },
      "source": [
        "plt.subplot(221)\n",
        "plt.imshow(x_train[0],cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4158641eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACFCAYAAACAJLCMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pNbBgUiel5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1298bba1-38f5-4a09-edcb-9a385ffaf913"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qv1046ZeMAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "1aa3a453-e09e-44f5-90a8-6a9d9af16340"
      },
      "source": [
        "plt.subplot(221)\n",
        "plt.imshow(x_train[55],cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4147206518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACFCAYAAACAJLCMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBQ-bdlzeQSN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "faf33e19-dfb2-40d8-f26e-091eb90a20b2"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data\",one_hot=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20QwsY1SfQRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_nodes_hl1 = 500 #num of nodes in hid layer 1\n",
        "n_nodes_hl2 = 500 #num of nodes in hid layer 2\n",
        "n_nodes_hl3 = 500 #num of nodes in hid layer 3\n",
        "\n",
        "n_classes = 10 # as v hv 10 digits 0 to 9\n",
        "batch_size = 100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TtI5GKqfimn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder('float',[None,784])\n",
        "y = tf.placeholder('float',[None,n_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgLaHXddf6VM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "068c4f5c-44d5-4c7d-e959-254b3d895ea7"
      },
      "source": [
        "test = tf.random_normal([784,500])\n",
        "print(test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"random_normal_1:0\", shape=(784, 500), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbm-7iJngF4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neuralnetworkmodel(data):\n",
        "  \n",
        "  hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784,n_nodes_hl1])),\n",
        "                    'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
        "    # 784 rnd norml distr nmbrs with a size of n_nds_hl1\n",
        "  hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1,n_nodes_hl2])),\n",
        "                    'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
        "    # the ip for layer2 is the op of lyr1\n",
        "    # so n_nodes_hl1 bcms the ip \n",
        "    # nd n_nodes_hl2 bcms the op of ly2\n",
        "  hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2,n_nodes_hl3])),\n",
        "                    'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
        "  output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3,n_classes])), #n_clss is a vec of 10 neurons with 10 dfrnt\n",
        "                   # vals which r then cmprd with encded vals of real nums in the pic\n",
        "                    'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
        "    # layer1\n",
        "  l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']),hidden_1_layer['biases'])\n",
        "    # v r multiplying data with hdn layer 1 with the wts nd then add the bias\n",
        "    \n",
        "    #nxt v need to add the activ func \n",
        "    # nd the best one os relu\n",
        "  l1 = tf.nn.relu(l1) #this will put the op of act func in l1\n",
        "  l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']),hidden_2_layer['biases'])\n",
        "  l2 = tf.nn.relu(l2) #this will put the op of act func in l\n",
        "  l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']),hidden_3_layer['biases'])\n",
        "  l3 = tf.nn.relu(l3) #this will put the op of act func in l\n",
        "  output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
        "    #output = tf.nn.relu(l3) #this will put the op of act func in l\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iC2oCpGhrVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainneuralnetwork(x):\n",
        "    prediction = neuralnetworkmodel(x)\n",
        "    # next v need to cmpr our prediction with encoded val\n",
        "    # to do this v use the cost func\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y)) \n",
        "    # softmax_cross_entropy_with_logits refers to logstc regr\n",
        "    # this is used for reducing the cost\n",
        "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "    # this is the stochastic grad desc\n",
        "    epochs = 3\n",
        "    # v hv 60k training imgs \n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer()) # this will initialize the placeholder global vars v created on the top\n",
        "        \n",
        "        for ep in range(epochs):\n",
        "            epoch_loss = 0 \n",
        "            for _ in range(int(mnist.train.num_examples/batch_size)): #same as 60k/100\n",
        "                epoch_x,epoch_y = mnist.train.next_batch(batch_size) # for ea ep for ea btch size\n",
        "                # say v r creating 100 images of our training data\n",
        "                _,c = sess.run([optimizer,cost],feed_dict={x:epoch_x, y:epoch_y})\n",
        "                epoch_loss+=c # this will calc the tot loss for 1 epoch aftr going thru all the 600 btchs\n",
        "                # of a 100 pics\n",
        "                print('Epoch:', ep, ' completed out of ', epochs, ' loss', epoch_loss)\n",
        "            correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
        "            # the op v get is a vec\n",
        "            accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
        "            print('Accuracy: ', accuracy.eval({x:mnist.test.images,y:mnist.test.labels})) # here is where the 10k imgs r taken\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBS4qXbfh1ON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainneuralnetwork(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}